{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8e33e4e",
   "metadata": {},
   "source": [
    "### Instalar las dependeciencias necesarias para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f059b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install openai\n",
    "%pip install python-dotenv\n",
    "%pip install \"unstructured[local-inference]\"\n",
    "%pip install chromadb\n",
    "%pip install tiktoken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de5b6592",
   "metadata": {},
   "source": [
    "### Cargar las variables de entorno\n",
    "\n",
    "Recuerda renombrar el archivo `.env.example` a `.env.local` y rellenar los campos con tus credenciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5166d759",
   "metadata": {},
   "source": [
    "### Cargar libro\n",
    "\n",
    "Libro descargado desde el proyecto Elejandría\n",
    "\n",
    "[Crimen y Castigo de Dostoyevski](https://www.elejandria.com/libro/crimen-y-castigo/dostoyevski-fiodor/146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"crimen_y_castigo.pdf\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Existen {len(data)} documento(s) en tu archivo')\n",
    "print (f'Con un total de {len(data[0].page_content)} caracteres')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8af9b604",
   "metadata": {},
   "source": [
    "### Dividir el documento en bloques mas pequeños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b993ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879873a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Despues de dividir el documento, ahora existen {len(texts)} textos')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "838b2843",
   "metadata": {},
   "source": [
    "### Embeddings de los bloques\n",
    "\n",
    "Crear los embeddings a partir de los los textos generados en el paso anterior.\n",
    "Esto lo hago para que la búsqueda semántica sea mas eficiente y ademas evitamos la perdida de contexto por parte de GPT.\n",
    "\n",
    "Base de datos usada: [Chroma](https://www.trychroma.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34929595",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_query = \"¿Cuál es el crimen que comete el protagonista, Rodion Raskólnikov, y por qué lo comete?\"\n",
    "testing_docs = db.similarity_search(testing_query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6318220",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Documentos encontrados que se ajustan a la pregunta: {len(docs)} documento(s)')\n",
    "print(f'Contenido del primer documento: {testing_docs[0].page_content}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c35dcd9",
   "metadata": {},
   "source": [
    "### Pregunta y respuesta\n",
    "Usando la base de datos creada en el paso anterior, realizamos la pregunta a GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"¿Cuál es el crimen que comete el protagonista, Rodion Raskólnikov, y por qué lo comete?\"\n",
    "docs = db.similarity_search(query, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd2b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "853cbd08",
   "metadata": {},
   "source": [
    "La respuesta es algo similar a esto:\n",
    "> Rodion Raskólnikov comete el asesinato y el robo de la vieja prestamista y su hermana Lisbeth. Lo comete por la miseria y el deseo de abrirse paso en la vida con los tres mil rublos que esperaba encontrar en casa de la víctima.\n",
    "\n",
    "Es importante destacar que **NO** estamos realizando un búsqueda \"clásica\" dentro del libro, sino que estamos usando como contexto para GPT la base de datos de Chroma que contiene multiples fragmentos del libro almacenados en forma de vectores.\n",
    "\n",
    "Ahora podemos hablar con un libro, y que el libro nos conteste.\n",
    "\n",
    "¡Se acabaron los deberes escolares!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415751f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
